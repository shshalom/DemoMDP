/**
 * AI-powered constraint generator
 *
 * Uses AIProvider interface to generate structured constraints from policy markdown.
 * Provider-agnostic: works with Anthropic, OpenAI, or any AIProvider implementation.
 */
/**
 * Generate constraints from policy markdown using AI
 *
 * Focuses on Detection section for efficient token usage.
 * Returns structured constraints suitable for PolicyCard.
 */
export async function generateConstraints(options) {
    const { provider, policyId, detectionSection, markdownBody, model } = options;
    // Use detection section if available, otherwise full markdown
    const inputText = detectionSection || markdownBody;
    if (!inputText || inputText.trim().length === 0) {
        return {
            confidence: 0,
            tokensUsed: 0,
            costUsd: 0,
            error: 'No detection section or markdown body provided',
        };
    }
    // Build prompt for AI
    const prompt = buildConstraintGenerationPrompt(policyId, inputText, !!detectionSection);
    // JSON schema for structured output
    const schema = {
        type: 'object',
        properties: {
            constraints: {
                type: 'object',
                description: 'Optimized prompts and hints for policy enforcement',
                properties: {
                    violation_check_prompt: {
                        type: 'string',
                        description: 'Ultra-short prompt to ask: does this code violate policy? (50-100 tokens)',
                    },
                    focus_patterns: {
                        type: 'array',
                        description: 'Keywords/patterns to help AI focus (hints, not regex)',
                        items: { type: 'string' },
                    },
                    file_types: {
                        type: 'array',
                        description: 'File extensions this policy applies to',
                        items: { type: 'string' },
                    },
                    severity: {
                        type: 'string',
                        enum: ['error', 'warning', 'info'],
                        description: 'Severity level for violations',
                    },
                },
                required: ['violation_check_prompt'],
            },
            confidence: {
                type: 'number',
                minimum: 0,
                maximum: 1,
                description: 'AI confidence in generated prompt (0.0-1.0)',
            },
            reasoning: {
                type: 'string',
                description: 'Brief explanation of prompt design',
            },
        },
        required: ['constraints', 'confidence'],
    };
    try {
        const response = await provider.complete({
            prompt,
            schema,
            model,
            temperature: 0.3, // Lower temperature for more consistent constraint generation
            max_tokens: 2000,
        });
        // Extract structured response
        const structured = response.structured;
        return {
            constraints: structured.constraints,
            confidence: structured.confidence || 0.7,
            tokensUsed: response.usage.total_tokens,
            costUsd: response.usage.cost_usd,
        };
    }
    catch (error) {
        return {
            confidence: 0,
            tokensUsed: 0,
            costUsd: 0,
            error: error instanceof Error ? error.message : String(error),
        };
    }
}
/**
 * Build prompt for constraint generation
 */
function buildConstraintGenerationPrompt(policyId, inputText, isDetectionSection) {
    const sectionContext = isDetectionSection
        ? 'The following is the Detection section from a policy document'
        : 'The following is a policy document';
    return `You are a policy prompt optimizer. Your task is to create ultra-efficient, focused prompts for code review.

# Policy Information
**Policy ID**: ${policyId}

# Input
${sectionContext}:

\`\`\`
${inputText}
\`\`\`

# Your Task
Generate an optimized prompt that will be used to ask AI "does this code violate the policy?"

The prompt MUST be:
1. **Ultra-short** (50-100 tokens): Every token costs money per PR
2. **Yes/no answerable**: First check is just "violation: yes or no"
3. **Focused**: Only what's needed to detect violations
4. **Self-contained**: No need to re-explain policy every time

Also provide:
- **Focus hints**: Patterns/keywords to help AI scan faster (e.g., "!", "as!", "try!")
- **File types**: Which files this applies to
- **Severity**: error, warning, or info

# Example Output
For "no force unwrap in Swift":
{
  "violation_check_prompt": "Contains force unwrap (! operator)? Answer yes or no only.",
  "focus_patterns": ["!", "as!", "try!"],
  "file_types": [".swift"],
  "severity": "error"
}

# Guidelines
- Make prompts as short as possible while staying clear
- Focus on detection, not explanation
- Patterns are hints, not regex (AI interprets them)
- Optimize for speed and cost

Output your response as structured JSON.`;
}
//# sourceMappingURL=constraint-generator.js.map