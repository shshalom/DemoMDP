/**
 * Policy Evaluator Types (M5)
 *
 * Defines the interface for policy evaluators that check compliance
 * against PolicyCard constraints.
 */
import type { PolicyCard } from '@mdp-framework/schemas/contracts';
/**
 * Evaluation context provided to evaluators
 */
export interface EvaluationContext {
    /** The policy being evaluated */
    policy: PolicyCard & {
        /** Full policy content in markdown (for AI evaluation) */
        _sourceMarkdown?: string;
    };
    /** PR context (if applicable) */
    pr?: {
        number: number;
        title: string;
        description: string;
        files: Array<{
            path: string;
            status: 'added' | 'modified' | 'deleted' | 'renamed';
            additions: number;
            deletions: number;
            changes: number;
            patch?: string;
            content?: string;
        }>;
        author: string;
        created_at: string;
        updated_at: string;
    };
    /** Feature context (if applicable) */
    feature?: {
        name: string;
        description: string;
        files: Array<{
            path: string;
            content: string;
        }>;
    };
    /** Additional metadata */
    metadata?: Record<string, unknown>;
}
/**
 * A single violation found by an evaluator
 */
export interface Violation {
    /** Human-readable message */
    message: string;
    /** Severity level */
    severity: 'info' | 'warning' | 'error';
    /** Location in code (if applicable) */
    location?: {
        file?: string;
        line?: number;
        column?: number;
        endLine?: number;
        endColumn?: number;
    };
    /** Suggested fix (unified diff format) */
    suggestedFix?: string;
    /** AI confidence score (0.0-1.0) - for AI-powered evaluators */
    confidence?: number;
    /** Metadata for the violation */
    metadata?: Record<string, unknown>;
}
/**
 * Result of evaluating a policy
 */
export interface EvaluationResult {
    /** Policy that was evaluated */
    policy_id: string;
    /** Policy version */
    policy_version: string;
    /** Overall status */
    status: 'pass' | 'warning' | 'fail';
    /** List of violations found */
    violations: Violation[];
    /** Evaluation metadata */
    metadata?: {
        /** Time taken to evaluate (ms) */
        duration_ms?: number;
        /** Number of files checked */
        files_checked?: number;
        /** Additional metadata */
        [key: string]: unknown;
    };
}
/**
 * Evaluator interface
 *
 * Each evaluator implements policy checking logic for a specific
 * policy type or family.
 */
export interface PolicyEvaluator {
    /** Unique identifier for this evaluator */
    readonly id: string;
    /** Policy IDs this evaluator can handle */
    readonly supportedPolicies: string[];
    /**
     * Check if this evaluator can handle a policy
     */
    canEvaluate(policy: PolicyCard): boolean;
    /**
     * Evaluate a policy against the given context
     */
    evaluate(context: EvaluationContext): Promise<EvaluationResult>;
}
/**
 * Evaluator registry for managing evaluators
 */
export interface EvaluatorRegistry {
    /**
     * Register an evaluator
     */
    register(evaluator: PolicyEvaluator): void;
    /**
     * Get evaluator for a policy
     */
    getEvaluator(policy: PolicyCard): PolicyEvaluator | null;
    /**
     * Evaluate a policy
     */
    evaluate(policy: PolicyCard, context: Omit<EvaluationContext, 'policy'>): Promise<EvaluationResult>;
}
/**
 * AI evaluation metadata (Stream 2)
 *
 * Tracks AI-powered evaluation metrics including cost, confidence, and performance.
 * All fields are optional to support hybrid evaluators that may use pattern-matching.
 */
export interface AIEvaluationMetadata {
    /**
     * Model used for evaluation
     */
    model?: string;
    /**
     * Total tokens consumed
     */
    tokens_used?: number;
    /**
     * Evaluation cost in USD
     */
    cost_usd?: number;
    /**
     * AI confidence score (0.0-1.0)
     * Average confidence across all violations
     */
    confidence_score?: number;
    /**
     * Evaluation latency
     */
    latency_ms?: number;
    /**
     * Whether pattern-matching fallback was used
     */
    fallback_used?: boolean;
    /**
     * LLM's reasoning (optional, for debugging)
     */
    reasoning?: string;
    /**
     * Additional metadata fields
     */
    [key: string]: unknown;
}
/**
 * AI-powered evaluator interface (Stream 2)
 *
 * Extends PolicyEvaluator with AI-specific capabilities like cost estimation
 * and confidence scoring.
 */
export interface AIEvaluator extends PolicyEvaluator {
    /**
     * Evaluate policy using AI
     */
    evaluate(context: EvaluationContext): Promise<EvaluationResult & {
        metadata?: AIEvaluationMetadata;
    }>;
    /**
     * Estimate cost before evaluation
     */
    estimateCost(context: EvaluationContext): Promise<{
        tokens: number;
        cost_usd: number;
        model: string;
    }>;
}
//# sourceMappingURL=types.d.ts.map